![](https://github.com/Kofoworola13/DSS/blob/main/Landing%20Page%20AB%20Testing%20Project/A_B%20Testing.jpg)

<a href="https://www.freepik.com/free-vector/ab-comparison-test-illustration_11062255.htm#fromView=search&page=1&position=5&uuid=698be4cb-759c-4b68-97c7-a961de7bca58">Image by macrovector on Freepik</a>


# A/B Testing Analysis: Evaluating Landing Page Performance ğŸš€

## Introduction ğŸ“Š

**A/B Testing** is a fundamental method in data-driven decision-making that involves comparing two versions of a webpage or app feature to determine which performs better. By splitting your audience into two groups and exposing them to different versions, you can measure which variant leads to better outcomes, such as higher conversion rates or improved user engagement. This technique is widely used in marketing, web development, and user experience design to optimize product performance based on empirical data.

This project analyzes the performance of two landing pages for **E-news Express**â€”an old page and a newly designed oneâ€”using A/B testing. The primary goal was to compare user engagement and conversion rates between the two versions, helping the company optimize its marketing efforts and increase subscription rates. The analysis not only highlights which landing page performs better but also offers actionable insights for further optimization.

## Project Overview ğŸ”

The analysis covers several key aspects of A/B testing, from formulating hypotheses to performing statistical tests, and interpreting the results. By comparing metrics like **time spent** on the pages and **conversion rates**, the project aims to provide clear data-driven recommendations for improving user experience and maximizing conversions.

### Objectives of the Project ğŸ¯

1. **Determine user engagement**: Measure and compare how much time users spend on the old and new landing pages.
2. **Assess conversion rates**: Analyze which landing page drives more users to subscribe or complete the desired action.
3. **Understand the impact of language preference**: Test whether the preferred language of users (English, French, or Spanish) influences time spent on the landing pages or conversion rates.
4. **Provide actionable recommendations**: Suggest data-backed changes to further enhance the performance of the new landing page.

## Analysis Process ğŸ”

### 1. **Hypothesis Testing** ğŸ§ 
We defined and tested several hypotheses to evaluate the effectiveness of the new landing page:
- **Null Hypothesis (Hâ‚€)**: The time spent on the new and old landing pages is the same.
- **Alternative Hypothesis (Hâ‚)**: Users spend more time on the new landing page.
We applied statistical methods to check if the observed differences in time spent and conversion rates were statistically significant.

### 2. **Statistical Tests and Assumptions** ğŸ“ˆ
We used the appropriate statistical tests such as the **t-test** and **Chi-square test** to validate our findings. Before performing these tests, we also verified key assumptions, such as the normality of the data distribution and sample independence.

### 3. **Key Findings** ğŸ“Œ

- **Time Spent on Landing Pages**: Users spent significantly more time (37.3% increase) on the new landing page compared to the old one.
- **Conversion Rate**: The new landing page had a 66% conversion rate, outperforming the old page's 42%.
- **Language Preference**: There was no significant difference in conversion rates across different languages (English, French, Spanish).

### 4. **Visualizations and Insights** ğŸ“Š
We created clear, informative visualizationsâ€”such as bar plots and density plotsâ€”that showcase the differences in user engagement and conversions across the two landing pages. These visual aids helped solidify our conclusions and guide the interpretation of results.

## Dataset ğŸ“

The dataset used for this analysis is available for download [here](https://github.com/Kofoworola13/DSS/raw/main/Landing%20Page%20AB%20Testing%20Project/abtest.csv). It contains user engagement data, conversion information, and language preferences for the A/B testing experiment.

## Conclusion & Recommendations âœ…

The new landing page performed significantly better in user engagement and conversion rates. Based on these results, the following recommendations are proposed:
- **Prioritize the New Landing Page**: Permanently adopt the new design and roll it out as the primary landing page.
- **Enhance Engagement**: Introduce additional interactive elements to improve user retention on the new page.
- **Continue A/B Testing**: Conduct regular A/B testing to monitor and optimize key design elements to maintain and improve performance over time.

## Tools & Libraries Used ğŸ› ï¸

- **Python**: For data analysis and hypothesis testing
- **Pandas & NumPy**: For data manipulation and preprocessing
- **Seaborn & Matplotlib**: For creating visualizations
- **SciPy**: For performing statistical tests

## Conclusion ğŸŒŸ

This A/B testing project has provided crucial insights into how design changes can influence user behavior and conversions. With these findings, **E-news Express** can confidently move forward with an optimized landing page that maximizes user engagement and subscription rates.

## Endnote âœï¸

This project was completed as part of my ongoing journey in data science, and Iâ€™m always excited to improve and learn more. Feel free to explore my GitHub for more projects like this!


*Created by Kofoworola Egbinola* â¤ï¸

